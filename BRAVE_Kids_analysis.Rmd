---
title: "BRAVE Kids 16S Analysis"
author: "Alex McCumber"
date: "11/3/2020"
output: html_document
---

```{r, include=FALSE}
library(dada2)
library(dplyr)
library(tibble)
library(purrr)
library(DECIPHER)
library(phyloseq)
library(ggplot2)
library(Biostrings)
library(ggtree)
library(ape)
library(stringr)

##needed to install the following packages for decontam:
#install.packages("isoband")
#install.packages("brio")
#install.packages("rematch2")
#install.packages("waldo")
#install.packages("digest")
#BiocManager::install("SIAMCAT")
require(siamcat)

library(devtools)
devtools::install_github("benjjneb/decontam")

library(decontam)
```

#Set filepaths and get sample names
```{r, Set filepaths}
path = "/sharedspace/BraveKids/"

list.files(path)

fnFs = sort(list.files(path, pattern="_R1_001.fastq", full.names = TRUE))
fnRs = sort(list.files(path, pattern="_R2_001.fastq", full.names = TRUE))

sample.names = sapply(strsplit(basename(fnFs),"_L001"), `[`,1)
```


```{r}
plotQualityProfile(fnFs[1:20],aggregate = TRUE)
```


```{r}
plotQualityProfile(fnRs[1:20], aggregate = TRUE)
```


```{r, set file path for where filtered reads will go}
filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```


```{bash}
gunzip /sharedspace/BraveKids/PCOV1001_S1_L001_R1_001.fastq.gz

head -n 20 /sharedspace/BraveKids/PCOV1001_S1_L001_R1_001.fastq 

gzip /sharedspace/BraveKids/PCOV1001_S1_L001_R1_001.fastq

```


#Filter and trim reads, using standard calls and trimming 20 off each end to remove primers
```{r}
#set multithread to False if you're running Windows

out <- filterAndTrim(fnFs, filtFs, fnRs, filtRs, truncLen=c(240,220),
              maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,
              compress=TRUE, multithread=T)
head(out)

as.data.frame(out) %>%
  mutate(., sum(reads.out)/sum(reads.in))

#Remove samples with 0 reads
filter.out = out %>%
  as.data.frame(.) %>%
  rownames_to_column('samples') %>%
  filter(., reads.out > 1) %>%
  column_to_rownames('samples')

filter.samples = out %>%
  as.data.frame(.) %>%
  rownames_to_column('samples') %>%
  filter(., reads.out > 1) %>%
  column_to_rownames('samples') %>%
  rownames(.) 

#Re-establish sample names now that some are gone
sample.names = sapply(strsplit(basename(filter.samples),"_L001"), `[`,1)

filtFs <- file.path(path, "filtered", paste0(sample.names, "_F_filt.fastq.gz"))
filtRs <- file.path(path, "filtered", paste0(sample.names, "_R_filt.fastq.gz"))
```


#Generate error function, dereplicating, and merging reads
```{r, include=false}
#set multithread to False if you're running Windows
errF = learnErrors(filtFs, multithread = T)
errR = learnErrors(filtRs, multithread = T)
names(filtFs) = sample.names
names(filtRs) = sample.names
mergers <- vector("list", length(sample.names))
names(mergers) <- sample.names
for(sam in sample.names) {
  cat("Processing:", sam, "\n")
    derepF <- derepFastq(filtFs[[sam]])
    ddF <- dada(derepF, err=errF, multithread=T)
    derepR <- derepFastq(filtRs[[sam]])
    ddR <- dada(derepR, err=errR, multithread=T)
    merger <- mergePairs(ddF, derepF, ddR, derepR)
    mergers[[sam]] <- merger
}
```

```{r}

```


```{r}
plotErrors(errF, nominalQ=TRUE)
```


```{r, making a sequence table}
seqtab = makeSequenceTable(mergers)

table(nchar(getSequences(seqtab)))

#Too many reads of lengths outside of anticipated amplicon size so will be removing all reads that don't fall within 250 to 260 bp
ncol(seqtab)

seqtab2=seqtab[,nchar(colnames(seqtab)) %in% seq(240,260)]

saveRDS(seqtab, "~/BRAVE_Kids/seqtab.RDS")

seqtab.nochim = removeBimeraDenovo(seqtab2, method="consensus", multithread = T, verbose = TRUE)

#3546 ASVs left
saveRDS(seqtab.nochim, "~/BRAVE_Kids/seqtab_nochim.RDS")

getN <- function(x) sum(getUniques(x))
track <- cbind(filter.out, sapply(mergers, getN), rowSums(seqtab.nochim))
colnames(track) <- c("input", "filtered", "merged", "nonchim")
rownames(track) <- sample.names
head(track)
colSums(track)
```

#Run this if you need to download the silva dataset v138 for IDTaxa function
```{bash, include = false}
wget http://www2.decipher.codes/Classification/TrainingSets/SILVA_SSU_r138_2019.RData -P ./silvadb
```


```{r}
dna <- DNAStringSet(getSequences(seqtab.nochim)) # Create a DNAStringSet from the ASVs

load("~/BRAVE_Kids/silvadb/SILVA_SSU_r138_2019.RData")

ids <- IdTaxa(dna, trainingSet, strand="top", processors=12, verbose=FALSE)

ranks <- c("domain", "phylum", "class", "order", "family", "genus", "species") # ranks of interest

# Convert the output object of class "Taxa" to a matrix analogous to the output from assignTaxonomy
taxid <- t(sapply(ids, function(x) {
        m <- match(ranks, x$rank)
        taxa <- x$taxon[m]
        taxa[startsWith(taxa, "unclassified_")] <- NA
        taxa
}))
colnames(taxid) <- ranks; rownames(taxid) <- getSequences(seqtab.nochim)
```

##Creation of tree, currently not working........

```{bash, make a tree with SEPP using gg backbone tree}
wget  "https://raw.github.com/smirarab/sepp-refs/master/gg/sepp-package.tar.bz"

tar xvfj sepp-package.tar.bz

cd sepp-package/sepp

python setup.py config -c

python setup.py install --user
```

```{r, make list of sequences in fasta file for tree making}
uniques=getUniques(seqtab.nochim)

sequences=names(uniques)

uniquesToFasta(uniques,fout = "~/BRAVE_Kids/seqs.fasta", ids=sequences)
```

```{bash}
./sepp-package/run-sepp.sh seqs.fasta BRAVE
```

```{r, view tree file with ggtree}
seq.tree = read.tree(file = "~/BRAVE_Kids/BRAVE_placement.tog.relabelled.tre") %>%
  keep.tip(., sequences)
```


#Import metadata and make dataframe
```{r}
metad = read.csv("~/BRAVE_Kids/metadata_16s_set1.csv") 

rownames(metad) = str_remove_all(metad$brave_id, "-")

metaDF = subset(metad, rownames(metad) %in% gsub("_.*","",sample.names))

rm(metad)
```

#Create phyloseq object
```{r}
#need to change seqtab.nochim to have same sample names as metadata
rownames(seqtab.nochim) = gsub("_.*","",rownames(seqtab.nochim))

ps = phyloseq(otu_table(seqtab.nochim, taxa_are_rows=FALSE), 
               sample_data(metaDF), 
               tax_table(taxid),
              phy_tree(seq.tree))

saveRDS(ps, "ps.RDS")
```

```{r}
subset_samples(ps, sample_data(ps)$brave_id == "extractNEGctrl") %>%
  prune_species(speciesSums(.) > 0, .)

#52 ASVs in extractNEGctrl

subset_samples(ps, sample_data(ps)$brave_id == "PCRneg") %>%
  prune_species(speciesSums(.) > 0, .)

#3 ASVs in PCRneg
```


#Decontam 
```{r}
contamdf.freq = isContaminant(ps, method="frequency", conc = "dna", threshold = 0.2)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)

#Identified 133 contaminant taxa in at 0.2
#remove contaminant taxa

ps.noncontam = prune_taxa(!contamdf.freq$contaminant, ps)
```

```{r}
plot_frequency(ps, taxa_names(ps)[sample(which(contamdf.freq$contaminant),4)], conc="dna") +
    xlab("DNA Concentration")
```


```{r}
subset_samples(ps.noncontam, sample_data(ps.noncontam)$brave_id == "extractNEGctrl") %>%
  prune_species(speciesSums(.) > 0, .)

#36 ASVs in extractNEGctrl

subset_samples(ps.noncontam, sample_data(ps.noncontam)$brave_id == "PCRneg") %>%
  prune_species(speciesSums(.) > 0, .)

#All PCR Neg Ctrl ASVs removed
```


```{r}
which(contamdf.freq$contaminant)
```

#Test for threshold 0.1 vs 0.2 for decontam
```{r}
contamdf.freq = isContaminant(ps, method="frequency", conc = "dna", threshold = 0.1)

hist(contamdf.freq$p)

table(contamdf.freq$contaminant)

#Identified 133 contaminant taxa in at 0.1
#remove contaminant taxa

ps.noncontam = prune_taxa(!contamdf.freq$contaminant, ps)

set.seed(42)
plot_frequency(ps, taxa_names(ps)[sample(which(contamdf.freq$contaminant),4)], conc="dna") +
    xlab("DNA Concentration")
```


#Remove contaminants ID'ed by decontam and remove ctrl and non-study samples
```{r}
ps.noncontam = prune_taxa(!contamdf.freq$contaminant, ps) %>%
  subset_samples(., sample_data(ps.noncontam)$sex != "NA") %>%
  prune_samples(sample_sums(.)>=2000, .) %>%
  transform_sample_counts(.,function(x) x/sum(x)) %>%
  prune_species(speciesSums(.) > 0, .) 
```

```{r}
ordinate(ps.noncontam, method = "PCoA", distance = "bray") %>%
plot_ordination(ps.noncontam, ., type="samples", color = "group", shape = "method_np")#+stat_ellipse()+theme_classic() 

```

```{r}
plot_richness(ps.noncontam, x="vl_log", color="method_np", measures="Shannon")

plot_richness(ps.noncontam, x="age", color="method_np", measures="Shannon")

plot_richness(ps.noncontam, x="timing_np", color="method_np", measures="Shannon")

metaDF.merge = mutate(metaDF, names = rownames(metaDF))

Shannon = estimate_richness(ps.noncontam, measures = "Shannon") %>%
  mutate(., names = rownames(.)) %>%
  left_join(., metaDF.merge, by = "names") %>%
  filter(., age != "NA")

ggplot(Shannon, aes(group, Shannon, fill = group)) + 
  geom_boxplot() +expand_limits(y=0)  + 
  theme_minimal() +
  facet_grid(~method_np)
  xlab(element_blank())

g2
```

```{r}
plot_bar(ps.noncontam, fill = "phylum") + geom_bar()
```


#Siamcat analysis
```{r}
ps.NP = subset_samples(ps.noncontam, sample_data(ps.noncontam)$method_np == "NP")

sc.obj <- siamcat(label = 'corona', case = 'Positive', phyloseq = ps.NP)

sc.obj <- filter.features(sc.obj, filter.method = 'abundance', cutoff = 1e-03)

#sc.obj <- filter.features(sc.obj, filter.method = 'prevalence', 
#                          cutoff = 0.05, feature.type = 'filtered')

sc.obj <- normalize.features(sc.obj, norm.method = 'log.std',
                             norm.param = list(log.n0=1e-05, sd.min.q=0))

sc.obj <- create.data.split(sc.obj, num.folds = 10, num.resample = 10)

sc.obj <- train.model(sc.obj, method='lasso')

sc.obj <- make.predictions(sc.obj)

sc.obj <- evaluate.predictions(sc.obj)

model.evaluation.plot(sc.obj, fn.plot = '~/BRAVE_Kids/eval_plot.pdf')

model.interpretation.plot(sc.obj, consens.thres = 0.7,
                          fn.plot = '~/BRAVE_Kids/interpretation_plot.pdf')
```

#Run Siamcat between asymptomatic and symp cases
```{r}
ps.NP = subset_samples(ps.noncontam, sample_data(ps.noncontam)$method_np == "NP") 

sc.obj <- siamcat(label = 'symptoms_any', case = '1', phyloseq = ps.NP)

sc.obj <- filter.features(sc.obj, filter.method = 'abundance', cutoff = 1e-03)

#sc.obj <- filter.features(sc.obj, filter.method = 'prevalence', 
#                          cutoff = 0.05, feature.type = 'filtered')

sc.obj <- normalize.features(sc.obj, norm.method = 'log.std',
                             norm.param = list(log.n0=1e-05, sd.min.q=0))

sc.obj <- create.data.split(sc.obj, num.folds = 5, num.resample = 5)

sc.obj <- train.model(sc.obj, method='lasso')

sc.obj <- make.predictions(sc.obj)

sc.obj <- evaluate.predictions(sc.obj)

model.evaluation.plot(sc.obj, fn.plot = '~/BRAVE_Kids/eval_plot.pdf')

model.interpretation.plot(sc.obj, consens.thres = 0.7,
                          fn.plot = '~/BRAVE_Kids/interpretation_plot.pdf')
```


```{r}

```

